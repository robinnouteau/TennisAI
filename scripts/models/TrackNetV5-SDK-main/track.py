# -*- coding: utf-8 -*-
import torch
import cv2
import numpy as np
import argparse
import os
import math # ç¡®ä¿ math è¢«å¯¼å…¥
import csv
from pathlib import Path
from tqdm import tqdm
from collections import deque
import time

# å¯¼å…¥ä½ é¡¹ç›®é‡Œçš„æ„å»ºå™¨å’Œæ¨¡å‹ï¼
from models_factory.builder import build_model
from datasets_factory.transforms.tracknet_transforms import (
    Resize, ConcatChannels
)

# --- 1. â€œæ¨¡å‹é…ç½®åº“â€ ---
MODEL_CONFIGS = {
    'v2': dict(
        type='TrackNetV2',
        backbone=dict(type='TrackNetV2Backbone', in_channels=9),
        neck=dict(type='TrackNetV2Neck'),
        head=dict(type='TrackNetV2Head', in_channels=64, out_channels=3)
    ),
    'v4': dict(
        type='TrackNetV4',
        backbone=dict(type='TrackNetV4Backbone', in_channels=9),
        neck=dict(type='TrackNetV4Neck'),
        head=dict(type='TrackNetV2Head', in_channels=64, out_channels=3)
    ),
    'v5': dict(
        type='TrackNetV5',
        backbone=dict(type='TrackNetV2Backbone', in_channels=13),
        neck=dict(type='TrackNetV2Neck'),
        head=dict(type='R_STRHead', in_channels=64, out_channels=3)
    )
}

# --- 2. è¾…åŠ©å‡½æ•° (âœ¨ å·²ä¿®æ”¹ï¼Œä¸ä½ çš„ Metric è„šæœ¬å¯¹é½) ---
def _heatmap_to_coords(heatmap: np.ndarray, threshold: int = 127):
    if heatmap.dtype != np.uint8:
        heatmap = heatmap.astype(np.uint8)

    _, binary_map = cv2.threshold(heatmap, threshold, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if contours:
        largest_contour = max(contours, key=cv2.contourArea)
        M = cv2.moments(largest_contour)
        if M["m00"] > 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            
            # --- âœ¨ æ–°å¢ï¼šæå–ç½®ä¿¡åº¦ ---
            # åˆ›å»ºä¸€ä¸ªæ©ç ï¼Œåªå…³æ³¨æœ€å¤§è½®å»“å†…çš„åŒºåŸŸ
            mask = np.zeros(heatmap.shape, dtype=np.uint8)
            cv2.drawContours(mask, [largest_contour], -1, 255, -1)
            
            # åœ¨åŸå§‹çƒ­åŠ›å›¾ä¸­æ‰¾åˆ°è¯¥åŒºåŸŸå†…çš„æœ€å¤§å€¼
            # minMaxLoc ä¼šè¿”å› (minVal, maxVal, minLoc, maxLoc)
            _, max_val, _, _ = cv2.minMaxLoc(heatmap, mask=mask)
            
            # å°† 0-255 å½’ä¸€åŒ–åˆ° 0-1 ä¹‹é—´ä½œä¸º conf
            conf = round(max_val / 255.0, 4)
            
            return cx, cy, conf

    return None

def draw_comet_tail(frame, points_deque, head_radius=8):
    """
    åŸºäºåŠå¾„è¡°å‡çš„åœ†ç‚¹è½¨è¿¹å¯è§†åŒ– (æ— è¿çº¿ç‰ˆ)
    :param frame: å½“å‰å›¾åƒå¸§ (BGR)
    :param points_deque: å­˜å‚¨åæ ‡çš„é˜Ÿåˆ—ï¼Œæ”¯æŒ (x, y) æˆ– (x, y, vis)
    :param head_radius: æœ€å‰ç«¯åœ†ç‚¹çš„æœ€å¤§åŠå¾„
    """
    # æ— éœ€åˆ›å»ºå…¨é»‘ overlayï¼Œå› ä¸ºæˆ‘ä»¬ç›´æ¥åœ¨åŸå›¾ç»˜åˆ¶å®å¿ƒåœ†
    # å¦‚æœéœ€è¦åŠé€æ˜æ•ˆæœï¼Œå¯ä»¥ä¿ç•™ overlay é€»è¾‘ï¼Œè¿™é‡Œé‡‡ç”¨ä½ è¦æ±‚çš„ç›´æ¥ç»˜åˆ¶
    
    q_len = len(points_deque)
    if q_len == 0:
        return frame

    for i, pt in enumerate(points_deque):
        # 1. å®‰å…¨æ£€æŸ¥ï¼šè·³è¿‡ç©ºç‚¹æˆ– NaN
        if pt is None:
            continue
            
        # å…¼å®¹å¤„ç†ï¼šæ”¯æŒ (x, y) æˆ– (x, y, vis/conf)
        if len(pt) >= 3:
            tx, ty, tvis = pt[:3]
            if tvis == 0 or tvis is None: continue 
        else:
            tx, ty = pt
            
        if tx is None or ty is None:
            continue

        # 2. è®¡ç®—åŠå¾„è¡°å‡ (æ ¸å¿ƒé€»è¾‘)
        # i=0 (æœ€æ—§) -> scale æœ€å°; i=q_len-1 (æœ€æ–°) -> scale=1.0
        scale = (i + 1) / q_len
        current_radius = int(head_radius * scale)

        # ç¡®ä¿åŠå¾„è‡³å°‘ä¸º 1
        current_radius = max(1, current_radius)

        # 3. ç»˜åˆ¶å®å¿ƒçƒ
        # ä½¿ç”¨ LINE_AA å¼€å¯æŠ—é”¯é½¿ï¼Œè®©åœ†ç‚¹è¾¹ç¼˜æ›´ä¸æ»‘
        cv2.circle(
            frame, 
            (int(tx), int(ty)), 
            current_radius, 
            (0, 0, 255), # çº¯çº¢è‰²
            -1,          # å®å¿ƒ
            lineType=cv2.LINE_AA
        )

    return frame


# --- 3. â€œæ ¸å¿ƒåŠ å·¥è½¦é—´â€: âœ¨ process_video (âœ¨ å·²ä¿®æ”¹) âœ¨ ---
def process_video(video_path: Path, model, device, args, output_root_dir: Path) -> dict:
    """
    å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆæ‰€æœ‰éœ€è¦çš„è¾“å‡ºæ–‡ä»¶ã€‚
    æ–°é€»è¾‘ï¼šä¸€æ¬¡è¯»å– 3 å¸§ï¼Œæ¨ç† 3 å¸§ï¼Œå†™å…¥ 3 å¸§ï¼Œç„¶åè·³ 3 å¸§ã€‚
    âœ¨ æ–°å¢: è¿”å›ä¸€ä¸ªåŒ…å«ç»Ÿè®¡æ•°æ®çš„å­—å…¸ã€‚
    """
    print(f"\nğŸ­ Processing video: {video_path.name}")
    
    video_output_dir = output_root_dir / video_path.stem
    video_output_dir.mkdir(parents=True, exist_ok=True)
    
    cap = cv2.VideoCapture(str(video_path))

    # --- âœ¨ æ–°å¢ï¼šè·å–è§†é¢‘åŸå§‹åˆ†è¾¨ç‡ ---
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    resolution_str = f"{width}x{height}"

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    input_size = (288, 512)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    
    trajectory_video_path = video_output_dir / f"{video_path.stem}_trajectory.mp4"
    comparison_video_path = video_output_dir / f"{video_path.stem}_comparison.mp4"
    csv_path = video_output_dir / f"{video_path.stem}_data.csv"
    
    writer_traj = cv2.VideoWriter(str(trajectory_video_path), fourcc, fps, (input_size[1], input_size[0]))
    writer_comp = cv2.VideoWriter(str(comparison_video_path), fourcc, fps, (input_size[1] * 2, input_size[0]))

    trajectory_points = deque(maxlen=fps) 
    
    csv_data = []
    detected_frames_count = 0
    
    # é¢„å¤„ç†è½¬æ¢ï¼ˆä¿æŒä¸å˜ï¼‰
    resizer = Resize(keys=['path_prev', 'path', 'path_next'], size=input_size)
    concatenator = ConcatChannels(
        keys=['path_prev', 'path', 'path_next'],
        output_key='image'
    )
    
    # --- æ–°çš„å¾ªç¯é€»è¾‘ ---
    frame_idx_counter = 0
    iteration_count = 0
    pbar = tqdm(total=total_frames, desc=f"Processing {video_path.stem}")
    start_time = time.time() # è®°å½•å¼€å§‹æ—¶é—´

    while cap.isOpened():
        # 1. ä¸€æ¬¡æ€§è¯»å– 3 å¸§
        ret1, frame1 = cap.read()
        ret2, frame2 = cap.read()
        ret3, frame3 = cap.read()

        # å¦‚æœä»»ä½•ä¸€å¸§è¯»å–å¤±è´¥ï¼ˆè§†é¢‘æœ«å°¾ï¼‰ï¼Œåˆ™ç»ˆæ­¢å¾ªç¯
        if not ret1 or not ret2 or not ret3:
            break

        # 2. å‡†å¤‡æ¨¡å‹è¾“å…¥
        frame1_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)
        frame2_rgb = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)
        frame3_rgb = cv2.cvtColor(frame3, cv2.COLOR_BGR2RGB)
        
        data_dict = {'path_prev': frame1_rgb, 'path': frame2_rgb, 'path_next': frame3_rgb}
        data_dict = resizer(data_dict)
        data_dict = concatenator(data_dict)
        
        resized_frames = [data_dict['path_prev'], data_dict['path'], data_dict['path_next']]
        
        image_np = data_dict['image']
        image_tensor = torch.from_numpy(image_np.transpose(2, 0, 1)).float().div(255).unsqueeze(0).to(device)

        # 3. æ‰¹é‡æ¨ç†
        with torch.no_grad():
            # heatmap_preds çš„å½¢çŠ¶æ˜¯ [1, 3, H, W]
            heatmap_preds = model(image_tensor)
        
        # ç§»é™¤ batch ç»´åº¦ï¼Œå¾—åˆ° (3, H, W) çš„ NumPy æ•°ç»„
        heatmaps_np = heatmap_preds.squeeze(0).cpu().numpy()
        threshold_uint8 = int(args.threshold * 255) # é˜ˆå€¼ä»ç„¶ç”±å‚æ•°æ§åˆ¶

        # 4. å¾ªç¯å¤„ç†è¿™ 3 å¸§çš„ç»“æœ
        for i in range(3):
            current_frame_idx = frame_idx_counter + i
            # ç¡®ä¿ä¸ä¼šå› ä¸ºæœ€åå‡ å¸§å‡‘ä¸æ»¡3å¸§è€Œå‡ºé”™
            if current_frame_idx >= total_frames:
                continue

            single_heatmap_np = heatmaps_np[i] # å½¢çŠ¶ (H, W)
            heatmap_uint8 = (single_heatmap_np * 255).astype(np.uint8)

            # (A) æå–åæ ‡ (âœ¨ å·²ä¿®æ”¹ï¼šç®€åŒ–è°ƒç”¨)
            coords = _heatmap_to_coords(
                heatmap_uint8, 
                threshold=threshold_uint8
            )
            
            # (B) è®°å½• CSV å’Œè½¨è¿¹
            if coords is not None:
                detected_frames_count += 1
                trajectory_points.append(coords)
                csv_row = {'frame_number': current_frame_idx, 'detected': 1, 'x': coords[0], 'y': coords[1]}
            else:
                trajectory_points.append(None)
                csv_row = {'frame_number': current_frame_idx, 'detected': 0, 'x': 0.0, 'y': 0.0}
            csv_data.append(csv_row)
            
            # (C) ç»˜åˆ¶å’Œå†™å…¥è§†é¢‘
            frame_to_draw = cv2.cvtColor(resized_frames[i], cv2.COLOR_RGB2BGR)
            
            # ç»˜åˆ¶è½¨è¿¹è§†é¢‘
            final_traj_frame = draw_comet_tail(frame_to_draw, trajectory_points)
            writer_traj.write(final_traj_frame)

            # ç»˜åˆ¶å¯¹æ¯”è§†é¢‘
            heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
            combined_frame = np.hstack((final_traj_frame, heatmap_color))
            writer_comp.write(combined_frame)

        # 5. æ›´æ–°è®¡æ•°å™¨å’Œè¿›åº¦æ¡ (å…³é”®ï¼)
        frame_idx_counter += 3
        iteration_count += 1
        pbar.update(3)
    
    # --- å¾ªç¯ç»“æŸåçš„æ¸…ç† ---

    end_time = time.time()
    total_duration = end_time - start_time
    # å¹³å‡æ¯ç§’å¤„ç†å¤šå°‘ä¸ª iteration (æ¯ iteration å¤„ç† 3 å¸§)
    avg_it_per_sec = iteration_count * 3 / total_duration if total_duration > 0 else 0
    print(f"â±ï¸  Processed {iteration_count * 3} frames of {resolution_str} in {total_duration:.2f} seconds. Avg: {avg_it_per_sec:.2f} frames/sec.")
    pbar.close() # å…³é—­è¿›åº¦æ¡

    detection_ratio = (detected_frames_count / total_frames) if total_frames > 0 else 0
    with open(csv_path, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['frame_number', 'detected', 'x', 'y'])
        writer.writeheader()
        writer.writerows(csv_data)
        f.write("\n")
        f.write(f"total_detected_frame,{detected_frames_count}\n")
        f.write(f"detection_ratio,{detection_ratio:.4f}\n")

    cap.release()
    writer_traj.release()
    writer_comp.release()
    print(f"âœ… Finished processing. Results saved in: {video_output_dir}")
    
    # âœ¨ æ–°å¢ï¼šè¿”å›ç»Ÿè®¡ç»“æœ
    stats = {
        'video_name': video_path.name,
        'detected_frames': detected_frames_count,
        'total_frames': total_frames,
        'detection_ratio': round(detection_ratio, 4)
    }
    return stats


# --- 4. â€œæ€»è°ƒåº¦å®¤â€: âœ¨ main (âœ¨ å·²ä¿®æ”¹) âœ¨ ---
def main():
    parser = argparse.ArgumentParser(description="TrackNet Batch Inference Pipeline")
    parser.add_argument('input_dir', type=str, help='Path to the directory containing input videos.')
    parser.add_argument('weights_path', type=str, help='Path to the model weights (.pth file).')
    
    # âœ¨ æ–°å¢æ¶æ„é€‰æ‹©å‚æ•°
    parser.add_argument(
        '--arch', 
        type=str, 
        required=True, 
        choices=['v2', 'v4', 'v5'], 
        help='Model architecture to use (v2, v4, or v5).'
    )
    
    parser.add_argument('--device', type=str, default='cuda:0', help='Device to use for inference (e.g., "cuda:0" or "cpu").')
    
    # âœ¨ å”¯ä¸€å¯è°ƒçš„åå¤„ç†å‚æ•° âœ¨
    parser.add_argument('--threshold', type=float, default=0.5, help='Confidence threshold for detection (0-1).')

    # âœ¨âœ¨âœ¨ å·²åˆ é™¤ --min-circularity å’Œ --min-area âœ¨âœ¨âœ¨
    
    args = parser.parse_args()

    # âœ¨ åŠ¨æ€è·å–æ¨¡å‹é…ç½®
    model_cfg = MODEL_CONFIGS.get(args.arch)
    if model_cfg is None:
        print(f"âŒ é”™è¯¯ï¼šæœªçŸ¥çš„æ¶æ„ '{args.arch}'ã€‚è¯·ä» 'v2', 'v4', 'v5' ä¸­é€‰æ‹©ã€‚")
        return
        
    print(f"ğŸš€ Starting Batch Inference Pipeline for [TrackNet {args.arch.upper()}]...")
    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    
    model = build_model(model_cfg)
    model.load_state_dict(torch.load(args.weights_path, map_location='cpu'))
    model.to(device).eval()
    print(f"âœ… Model loaded from {args.weights_path} and sent to {device}.")

    input_dir = Path(args.input_dir)
    
    # âœ¨ åŠ¨æ€è®¾ç½®è¾“å‡ºç›®å½•
    output_root_dir = input_dir / args.arch 
    output_root_dir.mkdir(exist_ok=True)
    
    print("ğŸ” Searching for .mp4 and .mov files...")
    video_files = []
    supported_formats = ['*.mp4', '*.mov', '*.MOV', '*.MP4']
    for fmt in supported_formats:
        video_files.extend(input_dir.glob(fmt))
    
    if not video_files:
        print(f"âŒ No supported video files (.mp4, .mov) found in {input_dir}. Exiting.")
        return
        
    video_files = sorted(list(set(video_files)))
    print(f"Found {len(video_files)} videos to process.")
    
    # âœ¨ 1. åˆå§‹åŒ–æ±‡æ€»åˆ—è¡¨
    summary_data_list = [] 
    
    for video_path in video_files:
        # âœ¨ 2. æ”¶é›†æ¯ä¸ªè§†é¢‘çš„è¿”å›ç»“æœ
        try:
            video_stats = process_video(video_path, model, device, args, output_root_dir)
            if video_stats:
                summary_data_list.append(video_stats)
        except Exception as e:
            print(f"âŒ ERROR processing {video_path.name}: {e}")
            print("Skipping this video and continuing...")

    # âœ¨ 3. å¾ªç¯ç»“æŸåï¼Œå†™å…¥å…¨å±€æ±‡æ€»CSV
    if summary_data_list:
        summary_csv_path = output_root_dir / f"_summary_report_{args.arch}.csv"
        print(f"\nğŸ“Š Writing summary report to {summary_csv_path}")
        
        fieldnames = ['video_name', 'detected_frames', 'total_frames', 'detection_ratio']
        # å®šä¹‰ä¸­æ–‡è¡¨å¤´
        chinese_header_map = {
            'video_name': 'è§†é¢‘å',
            'detected_frames': 'æ£€æµ‹åˆ°çš„çƒå¸§æ•°',
            'total_frames': 'è§†é¢‘æ€»å¸§æ•°',
            'detection_ratio': 'æ£€æµ‹æ¯”ç‡'
        }
        
        try:
            with open(summary_csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                # å†™å…¥UTF-8 BOMå¤´å’Œä¸­æ–‡è¡¨å¤´
                writer = csv.writer(f)
                writer.writerow([chinese_header_map[field] for field in fieldnames])
                
                # ä½¿ç”¨ DictWriter å†™å…¥æ•°æ®è¡Œ
                dict_writer = csv.DictWriter(f, fieldnames=fieldnames)
                dict_writer.writerows(summary_data_list)
        except Exception as e:
            print(f"âŒ ERROR writing summary CSV: {e}")
            
    print(f"\nğŸ‰ğŸ‰ğŸ‰ All videos processed! Check the results in: {output_root_dir} ğŸ‰ğŸ‰ğŸ‰")


if __name__ == '__main__':
    main()
